
data_dir = "E:\Project_2\Machine-Learning-for-Security-Analysts-master\Malicious URLs.csv"

# common imports
from cProfile import label
from cgi import test
import imp
from itertools import count
from tkinter import font
from turtle import color
from django import urls
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
import re

import streamlit as st
# matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer


#import scikit-learn models
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB


#import scikit-learn metric function
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns




# load the training dataset
print("-Loading CSV file-")
url_df = pd.read_csv(data_dir)

test_url = url_df['URLs'][14]

print("\n### CSV Data Loaded ###\n")

# print(url_df)

# perform train/test split

test_percentage = .2

train_df, test_df = train_test_split(url_df, test_size=test_percentage, random_state=42)

labels = train_df['Class']
test_labels = test_df['Class']

print("\n### Split Complete ###\n")

#Print counts of each class

print("- Counting splits -")
print("Training Samples:", len(train_df))
print("Testing Samples:", len(test_df))


# Graph counts of each class, for both training and testing
count_train_classes = pd.value_counts(train_df['Class'])
count_train_classes.plot(kind = 'bar', fontsize=16)
plt.title("Class count (Traning)", fontsize =20)
plt.xticks(rotation='horizontal')
plt.xlabel("Class", fontsize = 20)
plt.ylabel("Class Count", fontsize = 20)

# plt.show()

count_test_classes = pd.value_counts(test_df['Class'])
count_test_classes.plot(kind = 'bar', fontsize=16, colormap = 'ocean')
plt.title("Class count (testing)", fontsize =20)
plt.xticks(rotation='horizontal')
plt.xlabel("Class", fontsize = 20)
plt.ylabel("Class Count", fontsize = 20)

# plt.show()


def tokenizer(url):
  
  # Split by slash (/) and dash (-)
  tokens = re.split('[/-]', url)
  
  for i in tokens:
    # Include the splits extensions and subdomains
    if i.find(".") >= 0:
      dot_split = i.split('.')
      
      # Remove .com and www. since they're too common
      if "com" in dot_split:
        dot_split.remove("com")
      if "www" in dot_split:
        dot_split.remove("www")
      
      tokens += dot_split
      
  return tokens



print("\n- Full URL -\n")
print(test_url)

# Tokenize test URL
print("\n- Tokenized Output -\n")
tokenized_url = tokenizer(test_url)
print(tokenized_url)



print("- Training Count Vectorizer -")
cVec = CountVectorizer(tokenizer=tokenizer)
count_X = cVec.fit_transform(train_df['URLs'])

print("- Training TF-IDF Vectorizer -")
tVec = TfidfVectorizer(tokenizer=tokenizer)
tfidf_X = tVec.fit_transform(train_df['URLs'])


print("\n### Vectorizing Complete ###\n")



#print the count of each token from test_url(optional)

# Manually perform term count on test_url
for i in list(dict.fromkeys(tokenized_url)):
  print("{} - {}".format(tokenized_url.count(i), i))


example_cVec = CountVectorizer(tokenizer=tokenizer)
example_X = example_cVec.fit_transform([test_url])

print("\n- Count Vectorizer (Test URL) -\n")
print(example_X)

print()
print("=" * 50)
print()

example_tVec = TfidfVectorizer(tokenizer=tokenizer)
example_X = example_tVec.fit_transform([test_url])

print("\n- TFIDF Vectorizer (Test URL) -\n")
print(example_X)


# Vectorize the testing inputs
#   Use 'transform' instead of 'fit_transform' because we've already trained our vectorizers

print("- Count Vectorizer -")
test_count_X = cVec.transform(test_df['URLs'])

print("- TFIDF Vectorizer -")
test_tfidf_X = tVec.transform(test_df['URLs'])


print("\n### Vectorizing Complete ###\n")

# Define report generator

def generate_report(cmatrix, score, creport):
  """Generates and displays graphical reports
  Keyword arguments:
    cmatrix - Confusion matrix generated by the model
    score --- Score generated by the model
    creport - Classification Report generated by the model
    
  :Returns -- N/A
  """
  
  # Generate confusion matrix heatmap
  plt.figure(figsize=(5,5))
  sns.heatmap(cmatrix, 
              annot=True, 
              fmt="d", 
              linewidths=.5, 
              square = True, 
              cmap = 'Blues', 
              annot_kws={"size": 16}, 
              xticklabels=['bad', 'good'],
              yticklabels=['bad', 'good'])

  plt.xticks(rotation='horizontal', fontsize=16)
  plt.yticks(rotation='horizontal', fontsize=16)
  plt.xlabel('Actual Label', size=20);
  plt.ylabel('Predicted Label', size=20);

  title = 'Accuracy Score: {0:.4f}'.format(score)
  plt.title(title, size = 20);

  # Display classification report and confusion matrix
  print(creport)
  plt.show()
  

print("\n### Report Generator Defined ###\n")




# Multinomial Naive Bayesian with TF-IDF

# # Train the model
# mnb_tfidf = MultinomialNB()
# mnb_tfidf.fit(tfidf_X, labels)


# # Test the mode (score, predictions, confusion matrix, classification report)
# score_mnb_tfidf = mnb_tfidf.score(test_tfidf_X, test_labels)
# predictions_mnb_tfidf = mnb_tfidf.predict(test_tfidf_X)
# cmatrix_mnb_tfidf = confusion_matrix(predictions_mnb_tfidf, test_labels)
# creport_mnb_tfidf = classification_report(predictions_mnb_tfidf, test_labels)

# print("\n### Model Built ###\n")
# generate_report(cmatrix_mnb_tfidf, score_mnb_tfidf, creport_mnb_tfidf)


# Multinomial Naive Bayesian with Count Vectorizer

# Train the model
mnb_count = MultinomialNB(alpha = .1)
model = mnb_count.fit(count_X, labels)


# Test the mode (score, predictions, confusion matrix, classification report)
score_mnb_count = mnb_count.score(test_count_X, test_labels)
predictions_mnb_count = mnb_count.predict(test_count_X)
cmatrix_mnb_count = confusion_matrix(predictions_mnb_count, test_labels)
creport_mnb_count = classification_report(predictions_mnb_count, test_labels)

print("\n### Model Built ###\n")
generate_report(cmatrix_mnb_count, score_mnb_count, creport_mnb_count)

 
# Logistic Regression with TF-IDF

# Train the model
# lgs_tfidf = LogisticRegression(solver='lbfgs')
# lgs_tfidf.fit(tfidf_X, labels)


# # Test the mode (score, predictions, confusion matrix, classification report)
# score_lgs_tfidf = lgs_tfidf.score(test_tfidf_X, test_labels)
# predictions_lgs_tfidf = lgs_tfidf.predict(test_tfidf_X)
# cmatrix_lgs_tfidf = confusion_matrix(predictions_lgs_tfidf, test_labels)
# creport_lgs_tfidf = classification_report(predictions_lgs_tfidf, test_labels)

# print("\n### Model Built ###\n")
# generate_report(cmatrix_lgs_tfidf, score_lgs_tfidf, creport_lgs_tfidf)


# # Logistic Regression with Count Vectorizer

# # Train the model
# lgs_count = LogisticRegression(solver='lbfgs')
# lgs_count.fit(count_X, labels)


# # Test the mode (score, predictions, confusion matrix, classification report)
# score_lgs_count = lgs_count.score(test_count_X, test_labels)
# predictions_lgs_count = lgs_count.predict(test_count_X)
# cmatrix_lgs_count = confusion_matrix(predictions_lgs_count, test_labels)
# creport_lgs_count = classification_report(predictions_lgs_count, test_labels)

# print("\n### Model Built ###\n")
# generate_report(cmatrix_lgs_count, score_lgs_count, creport_lgs_count)


# lgs_count.predict(urls)

def predict_note_authentication(url):
    
    url_reshape = url.reshape(-1, 1)
    predictions_mnb_count = url_reshape.predict([url])
    print(predictions_mnb_count)
    return predictions_mnb_count




def main():
    st.title("PREDICT MALACIOUS URLs")
    html_temp = """
    <div style="background-color:tomato;padding:10px">
    <h2 style="color:white;text-align:center;"> Ml model to predict urls</h2>
    </div>
    """
    st.markdown(html_temp,unsafe_allow_html=True)
    url = st.text_input("URL","Type Here")
    result=""
    if st.button("Predict"):
        result=predict_note_authentication(url)
    st.success('The output is {}'.format(result))
    if st.button("About"):
        st.text("Lets LEarn")
        st.text("Built with Streamlit")

if __name__=='__main__':
    main()